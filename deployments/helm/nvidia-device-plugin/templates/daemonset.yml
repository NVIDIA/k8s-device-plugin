# Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

{{- if .Values.legacyDaemonsetAPI }}
apiVersion: extensions/v1beta1
{{- else }}
apiVersion: apps/v1
{{- end }}
kind: DaemonSet
metadata:
  name: {{ include "nvidia-device-plugin.fullname" . }}
  namespace: {{ .Values.namespace }}
  labels:
    {{- include "nvidia-device-plugin.labels" . | nindent 4 }}
spec:
  {{- if not .Values.legacyDaemonsetAPI }}
  selector:
    matchLabels:
      {{- include "nvidia-device-plugin.selectorLabels" . | nindent 6 }}
  {{- end }}
  {{- with .Values.updateStrategy }}
  updateStrategy:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  template:
    metadata:
      # This annotation is deprecated. Kept here for backward compatibility
      # See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        {{- include "nvidia-device-plugin.templateLabels" . | nindent 8 }}
    spec:
      # Mark this pod as a critical add-on; when enabled, the critical add-on
      # scheduler reserves resources for critical add-on pods so that they can
      # be rescheduled after a failure.
      # See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/
      priorityClassName: "system-node-critical"
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
      - image: {{ include "nvidia-device-plugin.fullimage" . }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        name: nvidia-device-plugin-ctr
        args:
        - "--mig-strategy={{ .Values.migStrategy }}"
        - "--pass-device-specs={{ .Values.compatWithCPUManager }}"
        - "--fail-on-init-error={{ .Values.failOnInitError }}"
        - "--device-list-strategy={{ .Values.deviceListStrategy }}"
        - "--device-id-strategy={{ .Values.deviceIDStrategy }}"
        - "--nvidia-driver-root={{ .Values.nvidiaDriverRoot }}"
        {{- with .Values.resourceConfig }}
        - "--resource-config={{ . }}"
        {{- end }}
        securityContext:
        {{- if ne (len .Values.securityContext) 0 }}
          {{- toYaml .Values.securityContext | nindent 10 }}
        {{- else if .Values.compatWithCPUManager }}
          privileged: true
        {{- else }}
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        {{- end }}
        volumeMounts:
          - name: device-plugin
            mountPath: /var/lib/kubelet/device-plugins
        {{- with .Values.resources }}
        resources:
          {{- toYaml . | nindent 10 }}
        {{- end }}
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
